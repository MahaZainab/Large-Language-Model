# Large Language Models

## LLM Quantization:
Quantization is a compression technique that involves mapping high precision values to the lower precision one.